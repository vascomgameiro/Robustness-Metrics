{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.data_loader_cifar import get_cifar_dataloaders\n",
    "from src.measures_sharpness import calculate_sharpness_metrics\n",
    "import src.model_constructor as constructor\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "def models_iterator(depths, filters_sizes, optimizers, drops, lrs):\n",
    "    models_to_train = []\n",
    "    for depth in depths:\n",
    "        fs = filters_sizes[str(depth)]\n",
    "        d = drops[str(depth)]\n",
    "        configurations = list(itertools.product(fs, optimizers, d, lrs))\n",
    "\n",
    "        for config in configurations:\n",
    "            filters_size, optimizer, drop, lr = config\n",
    "\n",
    "            nr_filters = filters_size[:depth]\n",
    "            conv_layers = constructor.Conv(nr_conv=depth, nr_filters=nr_filters, maxpool_batchnorm=True)\n",
    "            fc_size = filters_size[depth:]\n",
    "            act_fun = [\"ReLU\"] * depth\n",
    "            dropouts = drop\n",
    "            fc_layers = constructor.FC(\n",
    "                nr_fc=depth,\n",
    "                fc_size=fc_size,\n",
    "                act_funs=act_fun,\n",
    "                dropouts=dropouts,\n",
    "                in_features=conv_layers.finaldim,\n",
    "                num_classes=10,\n",
    "                batchnorm=True,\n",
    "            )\n",
    "\n",
    "            # Create the model using the CNN constructor\n",
    "            model = constructor.CNN(\n",
    "                conv_layers=conv_layers, fc_layers=fc_layers, num_classes=10, lr=lr, optim=optimizer\n",
    "            )\n",
    "\n",
    "            # Store the model and its parameters in the list\n",
    "            model_info = {\"name\": f\"{model.name}\", \"model\": model, \"params\": {\"lr\": lr, \"optimizer\": optimizer}}\n",
    "\n",
    "            models_to_train.append(model_info)\n",
    "\n",
    "    return models_to_train\n",
    "\n",
    "def accuracy_score(model, train_dataloader, device):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in train_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            preds = model(X).argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "depths = [2, 4]\n",
    "filters_sizes = {\n",
    "    \"2\": [[8, 16, 160, 80], [32, 64, 320, 160]],\n",
    "    \"4\": [[4, 8, 16, 32, 200, 200, 160, 80], [8, 16, 32, 64, 400, 320, 160, 80]],\n",
    "}\n",
    "lrs = [0.01, 0.001, \"scheduler\"]\n",
    "drops = {\"2\": [[0.0, 0.0], [0.5, 0.2]], \"4\": [[0.0] * 4, [0.5, 0.3, 0.3, 0.2]]}\n",
    "optimizers = [\"adam\", \"sgd\"]\n",
    "\n",
    "\n",
    "models_to_train = models_iterator(depths, filters_sizes, optimizers, drops, lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = get_cifar_dataloaders(path=Path(\"data/processed/cifar\"), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Accuracy: 0.96375\n",
      "Search depth 0, sigma: 2.5\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 611.6412420753312\n",
      "Weights Norm after normalzing 2.5000000868691115\n",
      "Deviation: 0.8627777777777778, Perturbed Accuracy: 0.10097222222222223\n",
      "Step: 1\n",
      "Weights Norm before normalzing 2.4999989097586317\n",
      "Deviation: -0.0072685185185185075, Perturbed Accuracy: 0.9710185185185185\n",
      "Step: 2\n",
      "Weights Norm before normalzing 2.5000063598860884\n",
      "Weights Norm after normalzing 2.500003637335877\n",
      "Step: 3\n",
      "Weights Norm before normalzing 2.500017977156069\n",
      "Weights Norm after normalzing 2.500001478145277\n",
      "Step: 4\n",
      "Weights Norm before normalzing 2.50002191045208\n",
      "Weights Norm after normalzing 2.50000099067673\n",
      "Deviation: -0.006712962962962976, Perturbed Accuracy: 0.970462962962963\n",
      "Step: 5\n",
      "Weights Norm before normalzing 2.500028382627763\n",
      "Weights Norm after normalzing 2.4999999464926073\n",
      "Step: 6\n",
      "Weights Norm before normalzing 2.5000406004596822\n",
      "Weights Norm after normalzing 2.5000007813620555\n",
      "Step: 7\n",
      "Weights Norm before normalzing 2.5000502789517602\n",
      "Weights Norm after normalzing 2.499999910470795\n",
      "Step: 8\n",
      "Weights Norm before normalzing 2.500063573360284\n",
      "Weights Norm after normalzing 2.499999614973756\n",
      "Step: 9\n",
      "Weights Norm before normalzing 2.5000836359666105\n",
      "Weights Norm after normalzing 2.500000035099219\n",
      "Deviation: -0.00462962962962965, Perturbed Accuracy: 0.9683796296296296\n",
      "Monte Carlo iteration 1\n",
      "Step: 0\n",
      "Weights Norm before normalzing 611.7591712164425\n",
      "Weights Norm after normalzing 2.4999999356776237\n",
      "Deviation: 0.8234722222222222, Perturbed Accuracy: 0.14027777777777778\n",
      "Step: 1\n",
      "Weights Norm before normalzing 2.500034537180997\n",
      "Weights Norm after normalzing 2.500000076665309\n",
      "Deviation: -0.0057870370370370905, Perturbed Accuracy: 0.9695370370370371\n",
      "Step: 2\n",
      "Weights Norm before normalzing 2.5000502893154257\n",
      "Weights Norm after normalzing 2.4999999196064877\n",
      "Step: 3\n",
      "Weights Norm before normalzing 2.50005757723174\n",
      "Weights Norm after normalzing 2.4999992658615895\n",
      "Step: 4\n",
      "Weights Norm before normalzing 2.500073016492034\n",
      "Weights Norm after normalzing 2.5000005061301125\n",
      "Deviation: -0.003935185185185208, Perturbed Accuracy: 0.9676851851851852\n",
      "Step: 5\n",
      "Weights Norm before normalzing 2.500092182113595\n",
      "Weights Norm after normalzing 2.4999998163897477\n",
      "Step: 6\n",
      "Weights Norm before normalzing 2.5001081181768705\n",
      "Weights Norm after normalzing 2.4999999226361966\n",
      "Step: 7\n",
      "Weights Norm before normalzing 2.5001440585616326\n",
      "Weights Norm after normalzing 2.4999999211751844\n",
      "Step: 8\n",
      "Weights Norm before normalzing 2.5001641630545604\n",
      "Weights Norm after normalzing 2.5000000462867313\n",
      "Step: 9\n",
      "Weights Norm before normalzing 2.50020777315775\n",
      "Weights Norm after normalzing 2.4999999440129606\n",
      "Deviation: -0.0005092592592592649, Perturbed Accuracy: 0.9642592592592593\n",
      "Monte Carlo iteration 2\n",
      "Step: 0\n",
      "Weights Norm before normalzing 612.0549099838281\n",
      "Weights Norm after normalzing 2.499999956408282\n",
      "Deviation: 0.86375, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 2.5000179517136836\n",
      "Weights Norm after normalzing 2.500001825646238\n",
      "Deviation: -0.006805555555555509, Perturbed Accuracy: 0.9705555555555555\n",
      "Step: 2\n",
      "Weights Norm before normalzing 2.5000319125887915\n",
      "Weights Norm after normalzing 2.500000009551877\n",
      "Step: 3\n",
      "Weights Norm before normalzing 2.500036766304715\n",
      "Weights Norm after normalzing 2.500000480319385\n",
      "Step: 4\n",
      "Weights Norm before normalzing 2.5000533143470833\n",
      "Weights Norm after normalzing 2.4999993756005225\n",
      "Deviation: -0.005324074074074092, Perturbed Accuracy: 0.9690740740740741\n",
      "Step: 5\n",
      "Weights Norm before normalzing 2.5000613278637718\n",
      "Weights Norm after normalzing 2.499999239618658\n",
      "Step: 6\n",
      "Weights Norm before normalzing 2.500081001819086\n",
      "Weights Norm after normalzing 2.5000000900370636\n",
      "Step: 7\n",
      "Weights Norm before normalzing 2.500099809982681\n",
      "Weights Norm after normalzing 2.500000078853917\n",
      "Step: 8\n",
      "Weights Norm before normalzing 2.5001234411258264\n",
      "Weights Norm after normalzing 2.499999947828473\n",
      "Step: 9\n",
      "Weights Norm before normalzing 2.5001596352283193\n",
      "Weights Norm after normalzing 2.5000003464345113\n",
      "Deviation: -0.0032870370370370328, Perturbed Accuracy: 0.967037037037037\n",
      "Monte Carlo iteration 3\n",
      "Step: 0\n",
      "Weights Norm before normalzing 611.546767409134\n",
      "Weights Norm after normalzing 2.4999999440740788\n",
      "Deviation: 0.8133796296296296, Perturbed Accuracy: 0.15037037037037038\n",
      "Step: 1\n",
      "Weights Norm before normalzing 2.5000024126481732\n",
      "Weights Norm after normalzing 2.5000018910730555\n",
      "Deviation: -0.007824074074074039, Perturbed Accuracy: 0.971574074074074\n",
      "Step: 2\n",
      "Weights Norm before normalzing 2.500008449293365\n",
      "Weights Norm after normalzing 2.500003306542199\n",
      "Step: 3\n",
      "Weights Norm before normalzing 2.500014776879091\n",
      "Weights Norm after normalzing 2.500003597067875\n",
      "Step: 4\n",
      "Weights Norm before normalzing 2.500024674367631\n",
      "Weights Norm after normalzing 2.5000000066473147\n",
      "Deviation: -0.007824074074074039, Perturbed Accuracy: 0.971574074074074\n",
      "Step: 5\n",
      "Weights Norm before normalzing 2.50002655895522\n",
      "Weights Norm after normalzing 2.49999990746728\n",
      "Step: 6\n",
      "Weights Norm before normalzing 2.5000382620940087\n",
      "Weights Norm after normalzing 2.50000031896632\n",
      "Step: 7\n",
      "Weights Norm before normalzing 2.500050444857714\n",
      "Weights Norm after normalzing 2.499999562691626\n",
      "Step: 8\n",
      "Weights Norm before normalzing 2.5000592081024573\n",
      "Weights Norm after normalzing 2.4999991278162566\n",
      "Step: 9\n",
      "Weights Norm before normalzing 2.500076832169249\n",
      "Weights Norm after normalzing 2.500000222987718\n",
      "Deviation: -0.00449074074074074, Perturbed Accuracy: 0.9682407407407407\n",
      "Monte Carlo iteration 4\n",
      "Step: 0\n",
      "Weights Norm before normalzing 611.2394222615843\n",
      "Weights Norm after normalzing 2.500000001056469\n",
      "Deviation: 0.8635185185185186, Perturbed Accuracy: 0.10023148148148148\n",
      "Step: 1\n",
      "Weights Norm before normalzing 2.4999944247388743\n",
      "Deviation: -0.00796296296296295, Perturbed Accuracy: 0.971712962962963\n",
      "Step: 2\n",
      "Weights Norm before normalzing 2.4999940241993928\n",
      "Step: 3\n",
      "Weights Norm before normalzing 2.500000486907036\n",
      "Weights Norm after normalzing 2.500000295595947\n",
      "Step: 4\n",
      "Weights Norm before normalzing 2.5000151543360505\n",
      "Weights Norm after normalzing 2.5000031192360077\n",
      "Deviation: -0.008333333333333304, Perturbed Accuracy: 0.9720833333333333\n",
      "Step: 5\n",
      "Weights Norm before normalzing 2.5000264785945756\n",
      "Weights Norm after normalzing 2.499999807876877\n",
      "Step: 6\n",
      "Weights Norm before normalzing 2.5000344232410723\n",
      "Weights Norm after normalzing 2.500000217085462\n",
      "Step: 7\n",
      "Weights Norm before normalzing 2.500049112280969\n",
      "Weights Norm after normalzing 2.499999863636909\n",
      "Step: 8\n",
      "Weights Norm before normalzing 2.500063725374451\n",
      "Weights Norm after normalzing 2.49999962396393\n",
      "Step: 9\n",
      "Weights Norm before normalzing 2.5000803207299374\n",
      "Weights Norm after normalzing 2.500000320974484\n",
      "Deviation: -0.004537037037037006, Perturbed Accuracy: 0.968287037037037\n",
      "Min accuracy: 0.9642592592592593, Deviation: 0.0005092592592592649\n",
      "Lower bound: 2.5, Upper bound: 5.0\n",
      "\n",
      "\n",
      "Search depth 1, sigma: 3.75\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 918.3399718564481\n",
      "Weights Norm after normalzing 3.7500001971144177\n",
      "Deviation: 0.86375, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 3.750026167302365\n",
      "Weights Norm after normalzing 3.749999946022095\n",
      "Deviation: -0.0065740740740740655, Perturbed Accuracy: 0.9703240740740741\n",
      "Step: 2\n",
      "Weights Norm before normalzing 3.750031453285706\n",
      "Weights Norm after normalzing 3.7499999154436705\n",
      "Step: 3\n",
      "Weights Norm before normalzing 3.7500394427238715\n",
      "Weights Norm after normalzing 3.7500006817047797\n",
      "Step: 4\n",
      "Weights Norm before normalzing 3.750049064577265\n",
      "Weights Norm after normalzing 3.749999960232526\n",
      "Deviation: -0.005509259259259269, Perturbed Accuracy: 0.9692592592592593\n",
      "Step: 5\n",
      "Weights Norm before normalzing 3.7500547319381825\n",
      "Weights Norm after normalzing 3.749999246707421\n",
      "Step: 6\n",
      "Weights Norm before normalzing 3.7500667675973665\n",
      "Weights Norm after normalzing 3.749999982266066\n",
      "Step: 7\n",
      "Weights Norm before normalzing 3.7500846860370807\n",
      "Weights Norm after normalzing 3.749999907876674\n",
      "Step: 8\n",
      "Weights Norm before normalzing 3.7500945987510392\n",
      "Weights Norm after normalzing 3.750000072503462\n",
      "Step: 9\n",
      "Weights Norm before normalzing 3.7501189410915963\n",
      "Weights Norm after normalzing 3.7499994666160017\n",
      "Deviation: -0.003148148148148122, Perturbed Accuracy: 0.9668981481481481\n",
      "Monte Carlo iteration 1\n",
      "Step: 0\n",
      "Weights Norm before normalzing 916.913543144836\n",
      "Weights Norm after normalzing 3.750000009740082\n",
      "Deviation: 0.86375, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 3.7500109747124433\n",
      "Weights Norm after normalzing 3.750003038974179\n",
      "Deviation: -0.007361111111111152, Perturbed Accuracy: 0.9711111111111111\n",
      "Step: 2\n",
      "Weights Norm before normalzing 3.7500189866389984\n",
      "Weights Norm after normalzing 3.7500012712706208\n",
      "Step: 3\n",
      "Weights Norm before normalzing 3.7500219285545473\n",
      "Weights Norm after normalzing 3.750000856847715\n",
      "Step: 4\n",
      "Weights Norm before normalzing 3.7500283601319904\n",
      "Weights Norm after normalzing 3.7499999244930216\n",
      "Deviation: -0.006111111111111067, Perturbed Accuracy: 0.9698611111111111\n",
      "Step: 5\n",
      "Weights Norm before normalzing 3.750035827707402\n",
      "Weights Norm after normalzing 3.7500005643814376\n",
      "Step: 6\n",
      "Weights Norm before normalzing 3.7500447433876993\n",
      "Weights Norm after normalzing 3.7500004315360513\n",
      "Step: 7\n",
      "Weights Norm before normalzing 3.750048996956369\n",
      "Weights Norm after normalzing 3.7499999313460037\n",
      "Step: 8\n",
      "Weights Norm before normalzing 3.750061969598952\n",
      "Weights Norm after normalzing 3.7499994024401055\n",
      "Step: 9\n",
      "Weights Norm before normalzing 3.7500771123903727\n",
      "Weights Norm after normalzing 3.750000429541469\n",
      "Deviation: -0.003750000000000031, Perturbed Accuracy: 0.9675\n",
      "Monte Carlo iteration 2\n",
      "Step: 0\n",
      "Weights Norm before normalzing 917.3476348217714\n",
      "Weights Norm after normalzing 3.7500000629030783\n",
      "Deviation: 0.86375, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 3.7499999385792755\n",
      "Deviation: -0.005833333333333357, Perturbed Accuracy: 0.9695833333333334\n",
      "Step: 2\n",
      "Weights Norm before normalzing 3.750002705289317\n",
      "Weights Norm after normalzing 3.7500021392783878\n",
      "Step: 3\n",
      "Weights Norm before normalzing 3.750006457133247\n",
      "Weights Norm after normalzing 3.7500036625173685\n",
      "Step: 4\n",
      "Weights Norm before normalzing 3.7500121055441165\n",
      "Weights Norm after normalzing 3.7500031952111716\n",
      "Deviation: -0.008333333333333304, Perturbed Accuracy: 0.9720833333333333\n",
      "Step: 5\n",
      "Weights Norm before normalzing 3.7500162608180925\n",
      "Weights Norm after normalzing 3.7500021948395084\n",
      "Step: 6\n",
      "Weights Norm before normalzing 3.750017166804655\n",
      "Weights Norm after normalzing 3.750001704909762\n",
      "Step: 7\n",
      "Weights Norm before normalzing 3.750020981009098\n",
      "Weights Norm after normalzing 3.7500010482654993\n",
      "Step: 8\n",
      "Weights Norm before normalzing 3.750024748682645\n",
      "Weights Norm after normalzing 3.7499999536899846\n",
      "Step: 9\n",
      "Weights Norm before normalzing 3.750028158820372\n",
      "Weights Norm after normalzing 3.7499997361951105\n",
      "Deviation: -0.0050000000000000044, Perturbed Accuracy: 0.96875\n",
      "Monte Carlo iteration 3\n",
      "Step: 0\n",
      "Weights Norm before normalzing 918.3858702745653\n",
      "Weights Norm after normalzing 3.7500003244184437\n",
      "Deviation: 0.86375, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 3.7500431145391193\n",
      "Weights Norm after normalzing 3.75000084539245\n",
      "Deviation: -0.006620370370370332, Perturbed Accuracy: 0.9703703703703703\n",
      "Step: 2\n",
      "Weights Norm before normalzing 3.7500530183137424\n",
      "Weights Norm after normalzing 3.7499994610280654\n",
      "Step: 3\n",
      "Weights Norm before normalzing 3.7500643412495562\n",
      "Weights Norm after normalzing 3.749999675177955\n",
      "Step: 4\n",
      "Weights Norm before normalzing 3.750078062800918\n",
      "Weights Norm after normalzing 3.7500002459700448\n",
      "Deviation: -0.002685185185185235, Perturbed Accuracy: 0.9664351851851852\n",
      "Step: 5\n",
      "Weights Norm before normalzing 3.750093688794118\n",
      "Weights Norm after normalzing 3.7500002315345458\n",
      "Step: 6\n",
      "Weights Norm before normalzing 3.750122771435812\n",
      "Weights Norm after normalzing 3.7499997691328875\n",
      "Step: 7\n",
      "Weights Norm before normalzing 3.750146119204937\n",
      "Weights Norm after normalzing 3.749999947325947\n",
      "Step: 8\n",
      "Weights Norm before normalzing 3.7501766890261123\n",
      "Weights Norm after normalzing 3.749999682100787\n",
      "Step: 9\n",
      "Weights Norm before normalzing 3.7502077682672175\n",
      "Weights Norm after normalzing 3.750000182384\n",
      "Deviation: -0.0008796296296296191, Perturbed Accuracy: 0.9646296296296296\n",
      "Monte Carlo iteration 4\n",
      "Step: 0\n",
      "Weights Norm before normalzing 917.009896737173\n",
      "Weights Norm after normalzing 3.7499998792540263\n",
      "Deviation: 0.86375, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 3.75001077688458\n",
      "Weights Norm after normalzing 3.7500029994900137\n",
      "Deviation: -0.007546296296296329, Perturbed Accuracy: 0.9712962962962963\n",
      "Step: 2\n",
      "Weights Norm before normalzing 3.7500180273659587\n",
      "Weights Norm after normalzing 3.7500012894217036\n",
      "Step: 3\n",
      "Weights Norm before normalzing 3.7500233078640646\n",
      "Weights Norm after normalzing 3.7500005455066363\n",
      "Step: 4\n",
      "Weights Norm before normalzing 3.7500284575281913\n",
      "Weights Norm after normalzing 3.749999993581635\n",
      "Deviation: -0.00796296296296295, Perturbed Accuracy: 0.971712962962963\n",
      "Step: 5\n",
      "Weights Norm before normalzing 3.750036564178544\n",
      "Weights Norm after normalzing 3.750000314398966\n",
      "Step: 6\n",
      "Weights Norm before normalzing 3.750041958846882\n",
      "Weights Norm after normalzing 3.7500005319908194\n",
      "Step: 7\n",
      "Weights Norm before normalzing 3.7500526032989647\n",
      "Weights Norm after normalzing 3.7499993494109773\n",
      "Step: 8\n",
      "Weights Norm before normalzing 3.7500650826452016\n",
      "Weights Norm after normalzing 3.750000064959749\n",
      "Step: 9\n",
      "Weights Norm before normalzing 3.7500816324028494\n",
      "Weights Norm after normalzing 3.750000027955199\n",
      "Deviation: -0.003657407407407387, Perturbed Accuracy: 0.9674074074074074\n",
      "Min accuracy: 0.9646296296296296, Deviation: 0.0008796296296296191\n",
      "Lower bound: 3.75, Upper bound: 5.0\n",
      "\n",
      "\n",
      "Search depth 2, sigma: 4.375\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 1069.2401821781896\n",
      "Weights Norm after normalzing 4.375000146543605\n",
      "Deviation: 0.86375, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 4.375034467833315\n",
      "Weights Norm after normalzing 4.375000253998268\n",
      "Deviation: -0.006249999999999978, Perturbed Accuracy: 0.97\n",
      "Step: 2\n",
      "Weights Norm before normalzing 4.375040298075688\n",
      "Weights Norm after normalzing 4.3750003938829085\n",
      "Step: 3\n",
      "Weights Norm before normalzing 4.375049119087138\n",
      "Weights Norm after normalzing 4.374999871810098\n",
      "Step: 4\n",
      "Weights Norm before normalzing 4.375058532693426\n",
      "Weights Norm after normalzing 4.374999230527917\n",
      "Deviation: -0.004861111111111094, Perturbed Accuracy: 0.9686111111111111\n",
      "Step: 5\n",
      "Weights Norm before normalzing 4.375072894702482\n",
      "Weights Norm after normalzing 4.375000441100958\n",
      "Step: 6\n",
      "Weights Norm before normalzing 4.375083896844225\n",
      "Weights Norm after normalzing 4.374999963851379\n",
      "Step: 7\n",
      "Weights Norm before normalzing 4.375102953605507\n",
      "Weights Norm after normalzing 4.375000131276567\n",
      "Step: 8\n",
      "Weights Norm before normalzing 4.375119990646895\n",
      "Weights Norm after normalzing 4.3749995114015405\n",
      "Step: 9\n",
      "Weights Norm before normalzing 4.375139382755897\n",
      "Weights Norm after normalzing 4.375000221468502\n",
      "Deviation: -0.0008796296296296191, Perturbed Accuracy: 0.9646296296296296\n",
      "Monte Carlo iteration 1\n",
      "Step: 0\n",
      "Weights Norm before normalzing 1071.94083739117\n",
      "Weights Norm after normalzing 4.3750002506654635\n",
      "Deviation: 0.86375, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 4.375012517948687\n",
      "Weights Norm after normalzing 4.375003194115954\n",
      "Deviation: -0.0072685185185185075, Perturbed Accuracy: 0.9710185185185185\n",
      "Step: 2\n",
      "Weights Norm before normalzing 4.375015743041824\n",
      "Weights Norm after normalzing 4.375002840659324\n",
      "Step: 3\n",
      "Weights Norm before normalzing 4.37501868001588\n",
      "Weights Norm after normalzing 4.375001238359495\n",
      "Step: 4\n",
      "Weights Norm before normalzing 4.375020631087994\n",
      "Weights Norm after normalzing 4.375000815785281\n",
      "Deviation: -0.007222222222222241, Perturbed Accuracy: 0.9709722222222222\n",
      "Step: 5\n",
      "Weights Norm before normalzing 4.375026349171679\n",
      "Weights Norm after normalzing 4.375000060921801\n",
      "Step: 6\n",
      "Weights Norm before normalzing 4.375027246581963\n",
      "Weights Norm after normalzing 4.375000019597688\n",
      "Step: 7\n",
      "Weights Norm before normalzing 4.375033680333036\n",
      "Weights Norm after normalzing 4.375000465448389\n",
      "Step: 8\n",
      "Weights Norm before normalzing 4.375042282998063\n",
      "Weights Norm after normalzing 4.375000707086651\n",
      "Step: 9\n",
      "Weights Norm before normalzing 4.3750487811073056\n",
      "Weights Norm after normalzing 4.374999813462737\n",
      "Deviation: -0.0036111111111111205, Perturbed Accuracy: 0.9673611111111111\n",
      "Monte Carlo iteration 2\n",
      "Step: 0\n",
      "Weights Norm before normalzing 1071.1593669337744\n",
      "Weights Norm after normalzing 4.37499992121011\n",
      "Deviation: 0.86375, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 4.375008595646563\n",
      "Weights Norm after normalzing 4.3750033077638335\n",
      "Deviation: -0.005277777777777826, Perturbed Accuracy: 0.9690277777777778\n",
      "Step: 2\n",
      "Weights Norm before normalzing 4.375011292145251\n",
      "Weights Norm after normalzing 4.375003150051124\n",
      "Step: 3\n",
      "Weights Norm before normalzing 4.375013988994847\n",
      "Weights Norm after normalzing 4.375003473399425\n",
      "Step: 4\n",
      "Weights Norm before normalzing 4.375016818801875\n",
      "Weights Norm after normalzing 4.375002422595524\n",
      "Deviation: -0.007685185185185239, Perturbed Accuracy: 0.9714351851851852\n",
      "Step: 5\n",
      "Weights Norm before normalzing 4.375019605380593\n",
      "Weights Norm after normalzing 4.375000905158969\n",
      "Step: 6\n",
      "Weights Norm before normalzing 4.37502281072457\n",
      "Weights Norm after normalzing 4.375000741578842\n",
      "Step: 7\n",
      "Weights Norm before normalzing 4.375024673805313\n",
      "Weights Norm after normalzing 4.374999737819382\n",
      "Step: 8\n",
      "Weights Norm before normalzing 4.375028288233042\n",
      "Weights Norm after normalzing 4.3749999971129\n",
      "Step: 9\n",
      "Weights Norm before normalzing 4.37503397683059\n",
      "Weights Norm after normalzing 4.375000198325138\n",
      "Deviation: -0.005185185185185182, Perturbed Accuracy: 0.9689351851851852\n",
      "Monte Carlo iteration 3\n",
      "Step: 0\n",
      "Weights Norm before normalzing 1070.3710293574238\n",
      "Weights Norm after normalzing 4.374999844861613\n",
      "Deviation: 0.8481944444444445, Perturbed Accuracy: 0.11555555555555555\n",
      "Step: 1\n",
      "Weights Norm before normalzing 4.3750132441785885\n",
      "Weights Norm after normalzing 4.3750034102491515\n",
      "Deviation: -0.005972222222222268, Perturbed Accuracy: 0.9697222222222223\n",
      "Step: 2\n",
      "Weights Norm before normalzing 4.37502028128487\n",
      "Weights Norm after normalzing 4.375000927211352\n",
      "Step: 3\n",
      "Weights Norm before normalzing 4.37502734747683\n",
      "Weights Norm after normalzing 4.374999841701769\n",
      "Step: 4\n",
      "Weights Norm before normalzing 4.375033740489358\n",
      "Weights Norm after normalzing 4.375000244262622\n",
      "Deviation: -0.004953703703703738, Perturbed Accuracy: 0.9687037037037037\n",
      "Step: 5\n",
      "Weights Norm before normalzing 4.3750451866299285\n",
      "Weights Norm after normalzing 4.375000683005314\n",
      "Step: 6\n",
      "Weights Norm before normalzing 4.37505835787321\n",
      "Weights Norm after normalzing 4.374999272370917\n",
      "Step: 7\n",
      "Weights Norm before normalzing 4.375070069535045\n",
      "Weights Norm after normalzing 4.375000225888958\n",
      "Step: 8\n",
      "Weights Norm before normalzing 4.3750900235244625\n",
      "Weights Norm after normalzing 4.375000078663495\n",
      "Step: 9\n",
      "Weights Norm before normalzing 4.375114589420119\n",
      "Weights Norm after normalzing 4.374999545960264\n",
      "Deviation: -0.002962962962962945, Perturbed Accuracy: 0.9667129629629629\n",
      "Monte Carlo iteration 4\n",
      "Step: 0\n",
      "Weights Norm before normalzing 1070.6084764496\n",
      "Weights Norm after normalzing 4.375000307689011\n",
      "Deviation: 0.86375, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 4.375042401600845\n",
      "Weights Norm after normalzing 4.3750003541487\n",
      "Deviation: -0.006296296296296355, Perturbed Accuracy: 0.9700462962962964\n",
      "Step: 2\n",
      "Weights Norm before normalzing 4.375055592020881\n",
      "Weights Norm after normalzing 4.374999181330793\n",
      "Step: 3\n",
      "Weights Norm before normalzing 4.375062636752328\n",
      "Weights Norm after normalzing 4.374999521230321\n",
      "Step: 4\n",
      "Weights Norm before normalzing 4.375071211264869\n",
      "Weights Norm after normalzing 4.375000212674157\n",
      "Deviation: -0.003935185185185208, Perturbed Accuracy: 0.9676851851851852\n",
      "Step: 5\n",
      "Weights Norm before normalzing 4.375088794050787\n",
      "Weights Norm after normalzing 4.375000087012137\n",
      "Step: 6\n",
      "Weights Norm before normalzing 4.375099199078593\n",
      "Weights Norm after normalzing 4.375000455606306\n",
      "Step: 7\n",
      "Weights Norm before normalzing 4.375129093467227\n",
      "Weights Norm after normalzing 4.375000203826593\n",
      "Step: 8\n",
      "Weights Norm before normalzing 4.375148348489763\n",
      "Weights Norm after normalzing 4.374999872056233\n",
      "Step: 9\n",
      "Weights Norm before normalzing 4.375171762486344\n",
      "Weights Norm after normalzing 4.374999598573343\n",
      "Deviation: -0.0005555555555555314, Perturbed Accuracy: 0.9643055555555555\n",
      "Min accuracy: 0.9643055555555555, Deviation: 0.0005555555555555314\n",
      "Lower bound: 4.375, Upper bound: 5.0\n",
      "\n",
      "\n",
      "Search depth 3, sigma: 4.6875\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 1144.3958879848954\n",
      "Weights Norm after normalzing 4.687499988786876\n"
     ]
    }
   ],
   "source": [
    "name = models_to_train[0]['name']\n",
    "model = models_to_train[0]['model']\n",
    "\n",
    "model_path = f\"models/{name}\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "trained_model_0 = deepcopy(models_to_train[0]['model'])\n",
    "untrained_model_0 = deepcopy(models_to_train[0]['model'])\n",
    "\n",
    "trained_model_0.load_state_dict(torch.load(model_path+'/trained.pt', map_location=device))\n",
    "untrained_model_0.load_state_dict(torch.load(model_path+'/untrained.pt', map_location=device))\n",
    "\n",
    "\n",
    "trained_model_0.to(device)\n",
    "untrained_model_0.to(device)\n",
    "\n",
    "trained_model_0.eval()\n",
    "accuracy_0 = accuracy_score(trained_model_0, train_dataloader, device)\n",
    "metrics_0 = calculate_sharpness_metrics(trained_model_0, train_dataloader, accuracy_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96375\n",
      "Metrics: {'Sharpness_Sigma': 2.5, 'Sharpness_Flatness': 0.16, 'Sharpness_Bound': 4.839417245035003}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_0}\")\n",
    "print(f\"Metrics: {metrics_0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search depth 0, sigma: 2.5\n",
      "Total L2 norm: 305.8198941013399\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.1\n",
      "Deviation: 0.79\n",
      "\n",
      "\n",
      "Search depth 1, sigma: 1.25\n",
      "Total L2 norm: 152.93942376159578\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.1\n",
      "Deviation: 0.79\n",
      "\n",
      "\n",
      "Search depth 2, sigma: 0.625\n",
      "Total L2 norm: 76.50673342187939\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.1\n",
      "Deviation: 0.79\n",
      "\n",
      "\n",
      "Search depth 3, sigma: 0.3125\n",
      "Total L2 norm: 38.221920456819106\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.1750925925925926\n",
      "Deviation: 0.7149074074074074\n",
      "\n",
      "\n",
      "Search depth 4, sigma: 0.15625\n",
      "Total L2 norm: 19.101761788882\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.14907407407407408\n",
      "Deviation: 0.740925925925926\n",
      "\n",
      "\n",
      "Search depth 5, sigma: 0.078125\n",
      "Total L2 norm: 9.566812153583099\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.20629629629629628\n",
      "Deviation: 0.6837037037037037\n",
      "\n",
      "\n",
      "Search depth 6, sigma: 0.0390625\n",
      "Total L2 norm: 4.776010641222307\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.40587962962962965\n",
      "Deviation: 0.48412037037037037\n",
      "\n",
      "\n",
      "Search depth 7, sigma: 0.01953125\n",
      "Total L2 norm: 2.3904744697322635\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.25930555555555557\n",
      "Deviation: 0.6306944444444444\n",
      "\n",
      "\n",
      "Search depth 8, sigma: 0.009765625\n",
      "Total L2 norm: 1.2000325690523599\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.28314814814814815\n",
      "Deviation: 0.6068518518518519\n",
      "\n",
      "\n",
      "Search depth 9, sigma: 0.0048828125\n",
      "Total L2 norm: 0.6040064204053949\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.28055555555555556\n",
      "Deviation: 0.6094444444444445\n",
      "\n",
      "\n",
      "Search depth 10, sigma: 0.00244140625\n",
      "Total L2 norm: 0.3138109630415019\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.28171296296296294\n",
      "Deviation: 0.608287037037037\n",
      "\n",
      "\n",
      "Search depth 11, sigma: 0.001220703125\n",
      "Total L2 norm: 0.17674674877188917\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.2776851851851852\n",
      "Deviation: 0.6123148148148148\n",
      "\n",
      "\n",
      "Search depth 12, sigma: 0.0006103515625\n",
      "Total L2 norm: 0.11917547908187653\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.2975\n",
      "Deviation: 0.5925\n",
      "\n",
      "\n",
      "Search depth 13, sigma: 0.00030517578125\n",
      "Total L2 norm: 0.1007370734616693\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.2801388888888889\n",
      "Deviation: 0.6098611111111112\n",
      "\n",
      "\n",
      "Search depth 14, sigma: 0.000152587890625\n",
      "Total L2 norm: 0.09612338175572516\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.2925462962962963\n",
      "Deviation: 0.5974537037037038\n",
      "\n",
      "\n",
      "Search depth 15, sigma: 7.62939453125e-05\n",
      "Total L2 norm: 0.09535300973952023\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.29106481481481483\n",
      "Deviation: 0.5989351851851852\n",
      "\n",
      "\n",
      "Search depth 16, sigma: 3.814697265625e-05\n",
      "Total L2 norm: 0.09416784586135943\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.2833333333333333\n",
      "Deviation: 0.6066666666666667\n",
      "\n",
      "\n",
      "Search depth 17, sigma: 1.9073486328125e-05\n",
      "Total L2 norm: 0.09358376421601762\n",
      "Early stopping triggered at ascent step 1 due to high deviation.\n",
      "Perturbed accuracy: 0.29939814814814814\n",
      "Deviation: 0.5906018518518519\n",
      "\n",
      "\n",
      "Desired deviation achieved or search bounds converged.\n",
      "Final sigma: 1.9073486328125e-05\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = models_to_train[1]['name']\n",
    "model = models_to_train[1]['model']\n",
    "\n",
    "model_path = f\"models/{name}\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "trained_model_1 = deepcopy(models_to_train[1]['model'])\n",
    "untrained_model_1 = deepcopy(models_to_train[1]['model'])\n",
    "\n",
    "trained_model_1.load_state_dict(torch.load(model_path+'/trained.pt', map_location=device))\n",
    "untrained_model_1.load_state_dict(torch.load(model_path+'/untrained.pt', map_location=device))\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_cifar_dataloaders(path=Path(\"data/processed/cifar\"), batch_size=32)\n",
    "\n",
    "trained_model_1.to(device)\n",
    "untrained_model_1.to(device)\n",
    "\n",
    "trained_model_1.eval()\n",
    "accuracy_1 = accuracy_score(trained_model_1, train_dataloader, device)\n",
    "metrics_1 = calculate_sharpness_metrics(trained_model_1, train_dataloader, accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "Metrics: {'Sharpness_MAG_Sigma': 0.015625, 'Sharpness_MAG_Flatness': 4096.0, 'Sharpness_MAG_Bound': 774.3067592056004}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_1}\")\n",
    "print(f\"Metrics: {metrics_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90375\n",
      "Search depth 0, sigma: 2.5\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 611.2427412058438\n",
      "Weights Norm after normalzing 2.5000002288492293\n",
      "Deviation: 0.7178240740740741, Perturbed Accuracy: 0.18592592592592594\n",
      "Step: 1\n",
      "Weights Norm before normalzing 2.500074739315126\n",
      "Weights Norm after normalzing 2.500000508045144\n",
      "Deviation: -4.6296296296266526e-05, Perturbed Accuracy: 0.9037962962962963\n",
      "Step: 2\n",
      "Weights Norm before normalzing 2.5001840692149786\n",
      "Weights Norm after normalzing 2.4999999466526783\n",
      "Step: 3\n",
      "Weights Norm before normalzing 2.5003290328349985\n",
      "Weights Norm after normalzing 2.4999999902705894\n",
      "Step: 4\n",
      "Weights Norm before normalzing 2.500558084903509\n",
      "Weights Norm after normalzing 2.5000001852982607\n",
      "Deviation: 0.0014351851851852615, Perturbed Accuracy: 0.9023148148148148\n",
      "Step: 5\n",
      "Weights Norm before normalzing 2.5008443147791612\n",
      "Weights Norm after normalzing 2.499999934353399\n",
      "Step: 6\n",
      "Weights Norm before normalzing 2.5012340219786764\n",
      "Weights Norm after normalzing 2.4999999697116433\n",
      "Step: 7\n",
      "Weights Norm before normalzing 2.501702227193152\n",
      "Weights Norm after normalzing 2.499999999330612\n",
      "Step: 8\n",
      "Weights Norm before normalzing 2.502360243475488\n",
      "Weights Norm after normalzing 2.5000002604443443\n",
      "Step: 9\n",
      "Weights Norm before normalzing 2.503162897819631\n",
      "Weights Norm after normalzing 2.5000000702391834\n",
      "Deviation: 0.03606481481481483, Perturbed Accuracy: 0.8676851851851852\n",
      "Monte Carlo iteration 1\n",
      "Step: 0\n",
      "Weights Norm before normalzing 612.2323693182068\n",
      "Weights Norm after normalzing 2.4999999850086168\n",
      "Deviation: 0.8037500000000001, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 2.500057938186569\n",
      "Weights Norm after normalzing 2.499998448544166\n",
      "Deviation: -0.0016203703703703276, Perturbed Accuracy: 0.9053703703703704\n",
      "Step: 2\n",
      "Weights Norm before normalzing 2.5001840084244624\n",
      "Weights Norm after normalzing 2.4999997638747917\n",
      "Step: 3\n",
      "Weights Norm before normalzing 2.5003575058681107\n",
      "Weights Norm after normalzing 2.499999767908583\n",
      "Step: 4\n",
      "Weights Norm before normalzing 2.500601616360708\n",
      "Weights Norm after normalzing 2.500000294757757\n",
      "Deviation: 0.0010648148148149073, Perturbed Accuracy: 0.9026851851851851\n",
      "Step: 5\n",
      "Weights Norm before normalzing 2.500955808279059\n",
      "Weights Norm after normalzing 2.4999999146675678\n",
      "Step: 6\n",
      "Weights Norm before normalzing 2.501403619571551\n",
      "Weights Norm after normalzing 2.500000063586048\n",
      "Step: 7\n",
      "Weights Norm before normalzing 2.5018522124001903\n",
      "Weights Norm after normalzing 2.499999960203422\n",
      "Step: 8\n",
      "Weights Norm before normalzing 2.5026662181380064\n",
      "Weights Norm after normalzing 2.4999998622282837\n",
      "Step: 9\n",
      "Weights Norm before normalzing 2.503440353088822\n",
      "Weights Norm after normalzing 2.500000193912994\n",
      "Deviation: 0.03995370370370377, Perturbed Accuracy: 0.8637962962962963\n",
      "Monte Carlo iteration 2\n",
      "Step: 0\n",
      "Weights Norm before normalzing 611.281588436743\n",
      "Weights Norm after normalzing 2.499999947790638\n",
      "Deviation: 0.8025462962962964, Perturbed Accuracy: 0.1012037037037037\n",
      "Step: 1\n",
      "Weights Norm before normalzing 2.5000679831934343\n",
      "Weights Norm after normalzing 2.499999940086854\n",
      "Deviation: -0.001388888888888884, Perturbed Accuracy: 0.9051388888888889\n",
      "Step: 2\n",
      "Weights Norm before normalzing 2.500224294190029\n",
      "Weights Norm after normalzing 2.4999997176171584\n",
      "Step: 3\n",
      "Weights Norm before normalzing 2.5004460074186263\n",
      "Weights Norm after normalzing 2.50000019950675\n",
      "Step: 4\n",
      "Weights Norm before normalzing 2.5007152883904635\n",
      "Weights Norm after normalzing 2.500000046525383\n",
      "Deviation: 0.009444444444444478, Perturbed Accuracy: 0.8943055555555556\n",
      "Step: 5\n",
      "Weights Norm before normalzing 2.5012069191769295\n",
      "Weights Norm after normalzing 2.4999998459679724\n",
      "Step: 6\n",
      "Weights Norm before normalzing 2.5017870810216225\n",
      "Weights Norm after normalzing 2.5000001355656387\n",
      "Step: 7\n",
      "Weights Norm before normalzing 2.5025170035457367\n",
      "Weights Norm after normalzing 2.500000004391768\n",
      "Step: 8\n",
      "Weights Norm before normalzing 2.503394983087447\n",
      "Weights Norm after normalzing 2.5000000721862294\n",
      "Step: 9\n",
      "Weights Norm before normalzing 2.504304552340399\n",
      "Weights Norm after normalzing 2.499999939973349\n",
      "Deviation: 0.04907407407407416, Perturbed Accuracy: 0.8546759259259259\n",
      "Min accuracy: 0.8546759259259259, Deviation: 0.04907407407407416\n",
      "Desired deviation achieved or search bounds converged.\n",
      "Final sigma: 2.5\n"
     ]
    }
   ],
   "source": [
    "name = models_to_train[3]['name']\n",
    "model = models_to_train[3]['model']\n",
    "\n",
    "model_path = f\"models/{name}\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "trained_model_3 = deepcopy(models_to_train[3]['model'])\n",
    "untrained_model_3 = deepcopy(models_to_train[3]['model'])\n",
    "\n",
    "trained_model_3.load_state_dict(torch.load(model_path+'/trained.pt', map_location=device))\n",
    "untrained_model_3.load_state_dict(torch.load(model_path+'/untrained.pt', map_location=device))\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_cifar_dataloaders(path=Path(\"data/processed/cifar\"), batch_size=32)\n",
    "\n",
    "trained_model_3.to(device)\n",
    "untrained_model_3.to(device)\n",
    "\n",
    "trained_model_3.eval()\n",
    "accuracy_3 = accuracy_score(trained_model_3, train_dataloader, device)\n",
    "metrics_3 = calculate_sharpness_metrics(trained_model_3, train_dataloader, accuracy_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90375\n",
      "Metrics: {'Sharpness_Sigma': 2.5, 'Sharpness_Flatness': 0.16, 'Sharpness_Bound': 4.839417245035003}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_3}\")\n",
    "print(f\"Metrics: {metrics_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7927314814814815\n",
      "Search depth 0, sigma: 2.5\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 611.5656972498446\n",
      "Weights Norm after normalzing 2.499999897828091\n",
      "Deviation: 0.6927314814814816, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 2.502014930356379\n",
      "Weights Norm after normalzing 2.4999999901570846\n",
      "Deviation: 0.05111111111111122, Perturbed Accuracy: 0.7416203703703703\n",
      "Step: 2\n",
      "Weights Norm before normalzing 2.5058608210684272\n",
      "Weights Norm after normalzing 2.500000066094798\n",
      "Step: 3\n",
      "Weights Norm before normalzing 2.5153177571830283\n",
      "Weights Norm after normalzing 2.499999998416752\n",
      "Step: 4\n",
      "Weights Norm before normalzing 2.5263097694190257\n",
      "Weights Norm after normalzing 2.5000000049127267\n",
      "Deviation: 0.5478240740740741, Perturbed Accuracy: 0.2449074074074074\n",
      "Early stopping triggered.\n",
      "Min accuracy: 0.2449074074074074, Deviation: 0.5478240740740741\n",
      "Lower bound: 0.0, Upper bound: 2.5\n",
      "\n",
      "\n",
      "Search depth 1, sigma: 1.25\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 306.1292524544753\n",
      "Weights Norm after normalzing 1.2500000257627104\n",
      "Deviation: 0.6927314814814816, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 1.2517579194683146\n",
      "Weights Norm after normalzing 1.2500000742002135\n",
      "Deviation: 0.027962962962962967, Perturbed Accuracy: 0.7647685185185186\n",
      "Step: 2\n",
      "Weights Norm before normalzing 1.2592050114275302\n",
      "Weights Norm after normalzing 1.2500000762665855\n",
      "Step: 3\n",
      "Weights Norm before normalzing 1.2799219980061691\n",
      "Weights Norm after normalzing 1.2499999763967933\n",
      "Step: 4\n",
      "Weights Norm before normalzing 1.3033498731764366\n",
      "Weights Norm after normalzing 1.2499999627383653\n",
      "Deviation: 0.49009259259259264, Perturbed Accuracy: 0.3026388888888889\n",
      "Early stopping triggered.\n",
      "Min accuracy: 0.3026388888888889, Deviation: 0.49009259259259264\n",
      "Lower bound: 0.0, Upper bound: 1.25\n",
      "\n",
      "\n",
      "Search depth 2, sigma: 0.625\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 152.83530664979196\n",
      "Weights Norm after normalzing 0.6250000471700314\n",
      "Deviation: 0.6927314814814816, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 0.6268238912071391\n",
      "Weights Norm after normalzing 0.6250000204949171\n",
      "Deviation: 0.0124537037037038, Perturbed Accuracy: 0.7802777777777777\n",
      "Step: 2\n",
      "Weights Norm before normalzing 0.6365675095139638\n",
      "Weights Norm after normalzing 0.6249999914569343\n",
      "Step: 3\n",
      "Weights Norm before normalzing 0.6674681036819549\n",
      "Weights Norm after normalzing 0.6249999501764231\n",
      "Step: 4\n",
      "Weights Norm before normalzing 0.7133054900217662\n",
      "Weights Norm after normalzing 0.6249999711712001\n",
      "Deviation: 0.42555555555555563, Perturbed Accuracy: 0.3671759259259259\n",
      "Early stopping triggered.\n",
      "Min accuracy: 0.3671759259259259, Deviation: 0.42555555555555563\n",
      "Lower bound: 0.0, Upper bound: 0.625\n",
      "\n",
      "\n",
      "Search depth 3, sigma: 0.3125\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 76.37454004020448\n",
      "Weights Norm after normalzing 0.3125000042658939\n",
      "Deviation: 0.6727314814814815, Perturbed Accuracy: 0.12\n",
      "Step: 1\n",
      "Weights Norm before normalzing 0.31703134093984725\n",
      "Weights Norm after normalzing 0.31250001710795866\n",
      "Deviation: 0.02486111111111111, Perturbed Accuracy: 0.7678703703703704\n",
      "Step: 2\n",
      "Weights Norm before normalzing 0.3455239683947105\n",
      "Weights Norm after normalzing 0.3125000126412485\n",
      "Step: 3\n",
      "Weights Norm before normalzing 0.4092236955974246\n",
      "Weights Norm after normalzing 0.31249997988706973\n",
      "Step: 4\n",
      "Weights Norm before normalzing 0.4661593469857643\n",
      "Weights Norm after normalzing 0.3125000270390944\n",
      "Deviation: 0.374212962962963, Perturbed Accuracy: 0.4185185185185185\n",
      "Early stopping triggered.\n",
      "Min accuracy: 0.4185185185185185, Deviation: 0.374212962962963\n",
      "Lower bound: 0.0, Upper bound: 0.3125\n",
      "\n",
      "\n",
      "Search depth 4, sigma: 0.15625\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 38.284128540814876\n",
      "Weights Norm after normalzing 0.15625000053732946\n",
      "Deviation: 0.6285648148148149, Perturbed Accuracy: 0.16416666666666666\n",
      "Step: 1\n",
      "Weights Norm before normalzing 0.16414751755291174\n",
      "Weights Norm after normalzing 0.15625000244908732\n",
      "Deviation: 0.019444444444444486, Perturbed Accuracy: 0.773287037037037\n",
      "Step: 2\n",
      "Weights Norm before normalzing 0.20996772571712607\n",
      "Weights Norm after normalzing 0.1562499882502375\n",
      "Step: 3\n",
      "Weights Norm before normalzing 0.2846783306992917\n",
      "Weights Norm after normalzing 0.15624999593637762\n",
      "Step: 4\n",
      "Weights Norm before normalzing 0.3292406369157278\n",
      "Weights Norm after normalzing 0.15625000018374066\n",
      "Deviation: 0.35245370370370377, Perturbed Accuracy: 0.44027777777777777\n",
      "Early stopping triggered.\n",
      "Min accuracy: 0.44027777777777777, Deviation: 0.35245370370370377\n",
      "Lower bound: 0.0, Upper bound: 0.15625\n",
      "\n",
      "\n",
      "Search depth 5, sigma: 0.078125\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 19.130356536111343\n",
      "Weights Norm after normalzing 0.07812499864012351\n",
      "Deviation: 0.6656018518518519, Perturbed Accuracy: 0.12712962962962962\n",
      "Step: 1\n",
      "Weights Norm before normalzing 0.09302350847604186\n",
      "Weights Norm after normalzing 0.078125002158049\n",
      "Deviation: 0.018981481481481488, Perturbed Accuracy: 0.77375\n",
      "Step: 2\n",
      "Weights Norm before normalzing 0.15222878499142758\n",
      "Weights Norm after normalzing 0.07812499989709068\n",
      "Step: 3\n",
      "Weights Norm before normalzing 0.204135463028056\n",
      "Weights Norm after normalzing 0.07812500153424365\n",
      "Step: 4\n",
      "Weights Norm before normalzing 0.22609165401276124\n",
      "Weights Norm after normalzing 0.0781250049558951\n",
      "Deviation: 0.32203703703703707, Perturbed Accuracy: 0.47069444444444447\n",
      "Early stopping triggered.\n",
      "Min accuracy: 0.47069444444444447, Deviation: 0.32203703703703707\n",
      "Lower bound: 0.0, Upper bound: 0.078125\n",
      "\n",
      "\n",
      "Search depth 6, sigma: 0.0390625\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 9.561592727018414\n",
      "Weights Norm after normalzing 0.03906250011841621\n",
      "Deviation: 0.45365740740740745, Perturbed Accuracy: 0.3390740740740741\n",
      "Step: 1\n",
      "Weights Norm before normalzing 0.06397385693440709\n",
      "Weights Norm after normalzing 0.039062496528344884\n",
      "Deviation: 0.02662037037037046, Perturbed Accuracy: 0.7661111111111111\n",
      "Step: 2\n",
      "Weights Norm before normalzing 0.11852313574779781\n",
      "Weights Norm after normalzing 0.03906249881735844\n",
      "Step: 3\n",
      "Weights Norm before normalzing 0.1410662653673767\n",
      "Weights Norm after normalzing 0.03906249807675599\n",
      "Step: 4\n",
      "Weights Norm before normalzing 0.14852509473845804\n",
      "Weights Norm after normalzing 0.03906249891403082\n",
      "Deviation: 0.2743055555555556, Perturbed Accuracy: 0.518425925925926\n",
      "Early stopping triggered.\n",
      "Min accuracy: 0.518425925925926, Deviation: 0.2743055555555556\n",
      "Lower bound: 0.0, Upper bound: 0.0390625\n",
      "\n",
      "\n",
      "Search depth 7, sigma: 0.01953125\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 4.782422104106656\n",
      "Weights Norm after normalzing 0.019531251466150878\n",
      "Deviation: 0.47537037037037044, Perturbed Accuracy: 0.3173611111111111\n",
      "Step: 1\n",
      "Weights Norm before normalzing 0.05697528259328639\n",
      "Weights Norm after normalzing 0.0195312474362309\n",
      "Deviation: 0.05398148148148152, Perturbed Accuracy: 0.73875\n",
      "Step: 2\n",
      "Weights Norm before normalzing 0.09424399508811841\n",
      "Weights Norm after normalzing 0.019531253364932222\n",
      "Step: 3\n",
      "Weights Norm before normalzing 0.1011950066514999\n",
      "Weights Norm after normalzing 0.019531258749640457\n",
      "Step: 4\n",
      "Weights Norm before normalzing 0.1033737535735744\n",
      "Weights Norm after normalzing 0.019531252381880238\n",
      "Deviation: 0.2063425925925927, Perturbed Accuracy: 0.5863888888888888\n",
      "Early stopping triggered.\n",
      "Min accuracy: 0.5863888888888888, Deviation: 0.2063425925925927\n",
      "Lower bound: 0.0, Upper bound: 0.01953125\n",
      "\n",
      "\n",
      "Search depth 8, sigma: 0.009765625\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 2.3860569858205745\n",
      "Weights Norm after normalzing 0.009765626383580086\n",
      "Deviation: 0.07083333333333341, Perturbed Accuracy: 0.7218981481481481\n",
      "Step: 1\n",
      "Weights Norm before normalzing 0.05221637028200423\n",
      "Weights Norm after normalzing 0.009765621183129234\n",
      "Deviation: 0.08546296296296307, Perturbed Accuracy: 0.7072685185185185\n",
      "Step: 2\n",
      "Weights Norm before normalzing 0.07423495198762421\n",
      "Weights Norm after normalzing 0.0097656206063089\n",
      "Step: 3\n",
      "Weights Norm before normalzing 0.0760778015445936\n",
      "Weights Norm after normalzing 0.009765634501920382\n",
      "Step: 4\n",
      "Weights Norm before normalzing 0.07630483598011972\n",
      "Weights Norm after normalzing 0.009765625768495994\n",
      "Deviation: 0.14574074074074084, Perturbed Accuracy: 0.6469907407407407\n",
      "Step: 5\n",
      "Weights Norm before normalzing 0.0772810478207362\n",
      "Weights Norm after normalzing 0.00976561994173201\n",
      "Step: 6\n",
      "Weights Norm before normalzing 0.07691432186512742\n",
      "Weights Norm after normalzing 0.009765629100001368\n",
      "Step: 7\n",
      "Weights Norm before normalzing 0.07782033944441483\n",
      "Weights Norm after normalzing 0.00976563294552438\n",
      "Step: 8\n",
      "Weights Norm before normalzing 0.07802276792065135\n",
      "Weights Norm after normalzing 0.009765628080321645\n",
      "Step: 9\n",
      "Weights Norm before normalzing 0.07726001262667723\n",
      "Weights Norm after normalzing 0.009765629037746368\n",
      "Deviation: 0.14328703703703705, Perturbed Accuracy: 0.6494444444444445\n",
      "Monte Carlo iteration 1\n",
      "Step: 0\n",
      "Weights Norm before normalzing 2.392816082041054\n",
      "Weights Norm after normalzing 0.009765627056162667\n",
      "Deviation: 0.26101851851851854, Perturbed Accuracy: 0.531712962962963\n",
      "Step: 1\n",
      "Weights Norm before normalzing 0.05142141120548325\n",
      "Weights Norm after normalzing 0.009765630243790482\n",
      "Deviation: 0.06486111111111115, Perturbed Accuracy: 0.7278703703703704\n",
      "Step: 2\n",
      "Weights Norm before normalzing 0.07383028749599078\n",
      "Weights Norm after normalzing 0.009765626528926466\n",
      "Step: 3\n",
      "Weights Norm before normalzing 0.07466726550830016\n",
      "Weights Norm after normalzing 0.009765624072768214\n",
      "Step: 4\n",
      "Weights Norm before normalzing 0.07522774234065224\n",
      "Weights Norm after normalzing 0.009765622041393005\n",
      "Deviation: 0.12935185185185194, Perturbed Accuracy: 0.6633796296296296\n",
      "Step: 5\n",
      "Weights Norm before normalzing 0.0752120052583745\n",
      "Weights Norm after normalzing 0.0097656197143145\n",
      "Step: 6\n",
      "Weights Norm before normalzing 0.07579341813152392\n",
      "Weights Norm after normalzing 0.009765624587635207\n",
      "Step: 7\n",
      "Weights Norm before normalzing 0.0757087739904663\n",
      "Weights Norm after normalzing 0.00976562102382478\n",
      "Step: 8\n",
      "Weights Norm before normalzing 0.07563253237074193\n",
      "Weights Norm after normalzing 0.009765622791973988\n",
      "Step: 9\n",
      "Weights Norm before normalzing 0.07696518234555765\n",
      "Weights Norm after normalzing 0.009765619317157127\n",
      "Deviation: 0.14787037037037043, Perturbed Accuracy: 0.6448611111111111\n",
      "Monte Carlo iteration 2\n",
      "Step: 0\n",
      "Weights Norm before normalzing 2.3913919088251085\n",
      "Weights Norm after normalzing 0.009765624138651636\n",
      "Deviation: 0.25268518518518523, Perturbed Accuracy: 0.5400462962962963\n",
      "Step: 1\n",
      "Weights Norm before normalzing 0.0536573835707448\n",
      "Weights Norm after normalzing 0.009765628223126478\n",
      "Deviation: 0.0854166666666667, Perturbed Accuracy: 0.7073148148148148\n",
      "Step: 2\n",
      "Weights Norm before normalzing 0.07247230495099229\n",
      "Weights Norm after normalzing 0.009765628973706022\n",
      "Step: 3\n",
      "Weights Norm before normalzing 0.07593457960538827\n",
      "Weights Norm after normalzing 0.00976562758651808\n",
      "Step: 4\n",
      "Weights Norm before normalzing 0.07740167536704799\n",
      "Weights Norm after normalzing 0.009765620815298241\n",
      "Deviation: 0.15300925925925934, Perturbed Accuracy: 0.6397222222222222\n",
      "Step: 5\n",
      "Weights Norm before normalzing 0.07751945098226813\n",
      "Weights Norm after normalzing 0.009765624968236363\n",
      "Step: 6\n",
      "Weights Norm before normalzing 0.07744673550507286\n",
      "Weights Norm after normalzing 0.009765633264438568\n",
      "Step: 7\n",
      "Weights Norm before normalzing 0.07579833012922192\n",
      "Weights Norm after normalzing 0.009765624322517373\n",
      "Step: 8\n",
      "Weights Norm before normalzing 0.07552553108045015\n",
      "Weights Norm after normalzing 0.009765618999334013\n",
      "Step: 9\n",
      "Weights Norm before normalzing 0.07742263643235121\n",
      "Weights Norm after normalzing 0.009765620707775235\n",
      "Deviation: 0.15583333333333338, Perturbed Accuracy: 0.6368981481481482\n",
      "Min accuracy: 0.6368981481481482, Deviation: 0.15583333333333338\n",
      "Desired deviation achieved or search bounds converged.\n",
      "Final sigma: 0.009765625\n"
     ]
    }
   ],
   "source": [
    "name = models_to_train[6]['name']\n",
    "model = models_to_train[6]['model']\n",
    "\n",
    "model_path = f\"models/{name}\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "trained_model_6 = deepcopy(models_to_train[6]['model'])\n",
    "untrained_model_6 = deepcopy(models_to_train[6]['model'])\n",
    "\n",
    "trained_model_6.load_state_dict(torch.load(model_path+'/trained.pt', map_location=device))\n",
    "untrained_model_6.load_state_dict(torch.load(model_path+'/untrained.pt', map_location=device))\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_cifar_dataloaders(path=Path(\"data/processed/cifar\"), batch_size=62)\n",
    "\n",
    "trained_model_6.to(device)\n",
    "untrained_model_6.to(device)\n",
    "\n",
    "trained_model_6.eval()\n",
    "accuracy_6 = accuracy_score(trained_model_6, train_dataloader, device)\n",
    "metrics_6 = calculate_sharpness_metrics(trained_model_6, train_dataloader, accuracy_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7927314814814815\n",
      "Metrics: {'Sharpness_Sigma': 0.009765625, 'Sharpness_Flatness': 10485.76, 'Sharpness_Bound': 1238.8908147289608}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_6}\")\n",
    "print(f\"Metrics: {metrics_6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9179166666666667\n",
      "Search depth 0, sigma: 2.5\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 611.2107325393315\n",
      "Weights Norm after normalzing 2.499999797949559\n",
      "Deviation: 0.8179166666666667, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 2.501332873604473\n",
      "Weights Norm after normalzing 2.5000000125553923\n",
      "Deviation: 0.006898148148148153, Perturbed Accuracy: 0.9110185185185186\n",
      "Step: 2\n",
      "Weights Norm before normalzing 2.5026079424099628\n",
      "Weights Norm after normalzing 2.499999983754242\n",
      "Step: 3\n",
      "Weights Norm before normalzing 2.5182218334169\n",
      "Weights Norm after normalzing 2.4999998971485162\n",
      "Step: 4\n",
      "Weights Norm before normalzing 2.53130932274195\n",
      "Weights Norm after normalzing 2.5000000504660416\n",
      "Deviation: 0.6983796296296296, Perturbed Accuracy: 0.21953703703703703\n",
      "Early stopping triggered.\n",
      "Min accuracy: 0.21953703703703703, Deviation: 0.6983796296296296\n",
      "Lower bound: 0.0, Upper bound: 2.5\n",
      "\n",
      "\n",
      "Search depth 1, sigma: 1.25\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 306.2506659091794\n",
      "Weights Norm after normalzing 1.2499999123625427\n",
      "Deviation: 0.8179166666666667, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 1.251044054567107\n",
      "Weights Norm after normalzing 1.2500000427549813\n",
      "Deviation: -0.0034259259259258323, Perturbed Accuracy: 0.9213425925925925\n",
      "Step: 2\n",
      "Weights Norm before normalzing 1.2531931598985189\n",
      "Weights Norm after normalzing 1.250000003099558\n",
      "Step: 3\n",
      "Weights Norm before normalzing 1.2595061016353057\n",
      "Weights Norm after normalzing 1.2499999909399775\n",
      "Step: 4\n",
      "Weights Norm before normalzing 1.2730734980845035\n",
      "Weights Norm after normalzing 1.2500000855361548\n",
      "Deviation: 0.3058333333333334, Perturbed Accuracy: 0.6120833333333333\n",
      "Early stopping triggered.\n",
      "Min accuracy: 0.6120833333333333, Deviation: 0.3058333333333334\n",
      "Lower bound: 0.0, Upper bound: 1.25\n",
      "\n",
      "\n",
      "Search depth 2, sigma: 0.625\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 152.8635853530003\n",
      "Weights Norm after normalzing 0.625000001648732\n",
      "Deviation: 0.8179166666666667, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 0.6257505458155255\n",
      "Weights Norm after normalzing 0.625000025908957\n",
      "Deviation: -0.013981481481481484, Perturbed Accuracy: 0.9318981481481482\n",
      "Step: 2\n",
      "Weights Norm before normalzing 0.6276990513859418\n",
      "Weights Norm after normalzing 0.624999987844785\n",
      "Step: 3\n",
      "Weights Norm before normalzing 0.6365268076662499\n",
      "Weights Norm after normalzing 0.6249999846397257\n",
      "Step: 4\n",
      "Weights Norm before normalzing 0.6747470719129985\n",
      "Weights Norm after normalzing 0.6249999850697348\n",
      "Deviation: 0.35018518518518527, Perturbed Accuracy: 0.5677314814814814\n",
      "Early stopping triggered.\n",
      "Min accuracy: 0.5677314814814814, Deviation: 0.35018518518518527\n",
      "Lower bound: 0.0, Upper bound: 0.625\n",
      "\n",
      "\n",
      "Search depth 3, sigma: 0.3125\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 76.48626641719854\n",
      "Weights Norm after normalzing 0.3125000055391865\n",
      "Deviation: 0.8179166666666667, Perturbed Accuracy: 0.1\n",
      "Step: 1\n",
      "Weights Norm before normalzing 0.31382022594267245\n",
      "Weights Norm after normalzing 0.3124999905678122\n",
      "Deviation: -0.0127314814814814, Perturbed Accuracy: 0.9306481481481481\n",
      "Step: 2\n",
      "Weights Norm before normalzing 0.32066223881049427\n",
      "Weights Norm after normalzing 0.31249998343628205\n",
      "Step: 3\n",
      "Weights Norm before normalzing 0.34975045883662187\n",
      "Weights Norm after normalzing 0.3124999994321115\n",
      "Step: 4\n",
      "Weights Norm before normalzing 0.4341512815083268\n",
      "Weights Norm after normalzing 0.3124999886524163\n",
      "Deviation: 0.4215740740740741, Perturbed Accuracy: 0.4963425925925926\n",
      "Early stopping triggered.\n",
      "Min accuracy: 0.4963425925925926, Deviation: 0.4215740740740741\n",
      "Lower bound: 0.0, Upper bound: 0.3125\n",
      "\n",
      "\n",
      "Search depth 4, sigma: 0.15625\n",
      "Monte Carlo iteration 0\n",
      "Step: 0\n",
      "Weights Norm before normalzing 38.23942429103249\n",
      "Weights Norm after normalzing 0.15625000840263942\n",
      "Deviation: 0.7035648148148148, Perturbed Accuracy: 0.21435185185185185\n",
      "Step: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m trained_model_8\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     19\u001b[0m accuracy_8 \u001b[38;5;241m=\u001b[39m accuracy_score(trained_model_8, train_dataloader, device)\n\u001b[1;32m---> 20\u001b[0m metrics_8 \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_sharpness_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_model_8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_8\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vasco\\repos\\Robustness-Metrics\\src\\measures_sharpness.py:392\u001b[0m, in \u001b[0;36mcalculate_sharpness_metrics\u001b[1;34m(model, dataloader, accuracy, device)\u001b[0m\n\u001b[0;32m    389\u001b[0m measures \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    390\u001b[0m num_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m--> 392\u001b[0m sharpness_sigma \u001b[38;5;241m=\u001b[39m \u001b[43msharpness_sigma_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_deviation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoise_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muniform_standard\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeviation_tolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbound_tolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mascent_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonte_carlo_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# sharpness_mag_sigma = sharpness_sigma_search(\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m#     model=model,\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;66;03m#     dataloader=dataloader,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m#     ascent_steps=20,\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m    424\u001b[0m measures[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSharpness_Sigma\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sharpness_sigma\n",
      "File \u001b[1;32mc:\\Users\\vasco\\repos\\Robustness-Metrics\\src\\measures_sharpness.py:228\u001b[0m, in \u001b[0;36msharpness_sigma_search\u001b[1;34m(model, dataloader, accuracy, target_deviation, device, noise_type, search_depth, monte_carlo_iter, upper, lower, deviation_tolerance, bound_tolerance, learning_rate, ascent_steps)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ascent_steps):\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 228\u001b[0m     \u001b[43mgradient_ascent_one_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m noise_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_magnitude_aware\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    230\u001b[0m         clip_perturbed_weights(model, sigma, original_weights)\n",
      "File \u001b[1;32mc:\\Users\\vasco\\repos\\Robustness-Metrics\\src\\measures_sharpness.py:191\u001b[0m, in \u001b[0;36mgradient_ascent_one_step\u001b[1;34m(model, dataloader, optimizer, device)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# Gradient ascent\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 191\u001b[0m     \u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\vasco\\repos\\Robustness-Metrics\\.venv\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vasco\\repos\\Robustness-Metrics\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vasco\\repos\\Robustness-Metrics\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "name = models_to_train[8]['name']\n",
    "model = models_to_train[8]['model']\n",
    "\n",
    "model_path = f\"models/{name}\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "trained_model_8 = deepcopy(models_to_train[8]['model'])\n",
    "untrained_model_8 = deepcopy(models_to_train[8]['model'])\n",
    "\n",
    "trained_model_8.load_state_dict(torch.load(model_path+'/trained.pt', map_location=device))\n",
    "untrained_model_8.load_state_dict(torch.load(model_path+'/untrained.pt', map_location=device))\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_cifar_dataloaders(path=Path(\"data/processed/cifar\"), batch_size=82)\n",
    "\n",
    "trained_model_8.to(device)\n",
    "untrained_model_8.to(device)\n",
    "\n",
    "trained_model_8.eval()\n",
    "accuracy_8 = accuracy_score(trained_model_8, train_dataloader, device)\n",
    "metrics_8 = calculate_sharpness_metrics(trained_model_8, train_dataloader, accuracy_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9179166666666667\n",
      "Metrics: {'Sharpness_Sigma': 0.01953125, 'Sharpness_Flatness': 2621.44, 'Sharpness_Bound': 619.4454073644804}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_8}\")\n",
    "print(f\"Metrics: {metrics_8}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
